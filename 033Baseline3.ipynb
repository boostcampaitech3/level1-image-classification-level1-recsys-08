{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd745c3a-e0ef-4b07-801b-b27fd903d0fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "#import cv2\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize, CenterCrop\n",
    "\n",
    "import timm\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19e0274a-14f9-4467-8d11-d7f5615eb346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed 고정\n",
    "def seed_everything(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if use multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "seed_everything(3033)\n",
    "\n",
    "class AgeGroup:\n",
    "    map_label = lambda x: 0 if int(x) < 30 else 1 if int(x) < 58 else 2\n",
    "\n",
    "class MaskBaseDataset(data.Dataset):\n",
    "    num_classes = 3 * 2 * 3\n",
    "\n",
    "    image_paths = []\n",
    "    mask_labels = []\n",
    "    gender_labels = []\n",
    "    age_labels = []\n",
    "\n",
    "    def __init__(self, img_dir, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.setup()\n",
    "\n",
    "    def set_transform(self, transform):\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def setup(self):\n",
    "        # mislabel 데이터들의 폴더명을 수정해서 폴더명을 기준으로 label 진행\n",
    "        profiles = os.listdir(self.img_dir)\n",
    "        for profile in profiles:\n",
    "            for file_name in os.listdir(os.path.join(self.img_dir, profile)):\n",
    "                _file_name, ext = os.path.splitext(file_name)\n",
    "                img_path = os.path.join(self.img_dir, profile, file_name)\n",
    "                self.image_paths.append(img_path)\n",
    "\n",
    "                # mask_label\n",
    "                mask_label = 0 if _file_name.startswith('mask') else ['mask','incorrect_mask','normal'].index(_file_name)\n",
    "                self.mask_labels.append(mask_label)\n",
    "\n",
    "                # gender_label\n",
    "                user_id, gender, area, age = profile.split(\"_\") # 000001_male_Asian_01\n",
    "                gender_label = ['male', 'female'].index(gender)\n",
    "                self.gender_labels.append(gender_label)\n",
    "                \n",
    "                # age_label\n",
    "                age_label = AgeGroup.map_label(age)\n",
    "                self.age_labels.append(age_label)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.image_paths[index]\n",
    "        image = Image.open(image_path)\n",
    "        \n",
    "        mask_label = self.mask_labels[index]\n",
    "        gender_label = self.gender_labels[index]\n",
    "        age_label = self.age_labels[index]\n",
    "\n",
    "        image_transform = self.transform(image)\n",
    "        return image_transform, mask_label,gender_label,age_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92314f98-b1ac-45af-8cc9-2ef860895fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom CosineAnnealingWarmRestarts (warm up start, max 감소 추가)\n",
    "# 출처: https://gaussian37.github.io/dl-pytorch-lr_scheduler/#custom-cosineannealingwarmrestarts-1\n",
    "\n",
    "import math\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "\n",
    "class CosineAnnealingWarmUpRestarts(_LRScheduler):\n",
    "    def __init__(self, optimizer, T_0, T_mult=1, eta_max=0.1, T_up=0, gamma=1., last_epoch=-1):\n",
    "        if T_0 <= 0 or not isinstance(T_0, int):\n",
    "            raise ValueError(\"Expected positive integer T_0, but got {}\".format(T_0))\n",
    "        if T_mult < 1 or not isinstance(T_mult, int):\n",
    "            raise ValueError(\"Expected integer T_mult >= 1, but got {}\".format(T_mult))\n",
    "        if T_up < 0 or not isinstance(T_up, int):\n",
    "            raise ValueError(\"Expected positive integer T_up, but got {}\".format(T_up))\n",
    "        self.T_0 = T_0\n",
    "        self.T_mult = T_mult\n",
    "        self.base_eta_max = eta_max\n",
    "        self.eta_max = eta_max\n",
    "        self.T_up = T_up\n",
    "        self.T_i = T_0\n",
    "        self.gamma = gamma\n",
    "        self.cycle = 0\n",
    "        self.T_cur = last_epoch\n",
    "        super(CosineAnnealingWarmUpRestarts, self).__init__(optimizer, last_epoch)\n",
    "    \n",
    "    def get_lr(self):\n",
    "        if self.T_cur == -1:\n",
    "            return self.base_lrs\n",
    "        elif self.T_cur < self.T_up:\n",
    "            return [(self.eta_max - base_lr)*self.T_cur / self.T_up + base_lr for base_lr in self.base_lrs]\n",
    "        else:\n",
    "            return [base_lr + (self.eta_max - base_lr) * (1 + math.cos(math.pi * (self.T_cur-self.T_up) / (self.T_i - self.T_up))) / 2\n",
    "                    for base_lr in self.base_lrs]\n",
    "\n",
    "    def step(self, epoch=None):\n",
    "        if epoch is None:\n",
    "            epoch = self.last_epoch + 1\n",
    "            self.T_cur = self.T_cur + 1\n",
    "            if self.T_cur >= self.T_i:\n",
    "                self.cycle += 1\n",
    "                self.T_cur = self.T_cur - self.T_i\n",
    "                self.T_i = (self.T_i - self.T_up) * self.T_mult + self.T_up\n",
    "        else:\n",
    "            if epoch >= self.T_0:\n",
    "                if self.T_mult == 1:\n",
    "                    self.T_cur = epoch % self.T_0\n",
    "                    self.cycle = epoch // self.T_0\n",
    "                else:\n",
    "                    n = int(math.log((epoch / self.T_0 * (self.T_mult - 1) + 1), self.T_mult))\n",
    "                    self.cycle = n\n",
    "                    self.T_cur = epoch - self.T_0 * (self.T_mult ** n - 1) / (self.T_mult - 1)\n",
    "                    self.T_i = self.T_0 * self.T_mult ** (n)\n",
    "            else:\n",
    "                self.T_i = self.T_0\n",
    "                self.T_cur = epoch\n",
    "                \n",
    "        self.eta_max = self.base_eta_max * (self.gamma**self.cycle)\n",
    "        self.last_epoch = math.floor(epoch)\n",
    "        for param_group, lr in zip(self.optimizer.param_groups, self.get_lr()):\n",
    "            param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf39366f-4bf0-4227-b273-ddef09a0d64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class cfg:\n",
    "    # 경로 설정\n",
    "    path = '../input/data/'\n",
    "    train_path = path + 'train/'\n",
    "    train_img_path = train_path + 'images/'\n",
    "    test_path = path + 'eval/'\n",
    "    test_img_path = test_path + 'images/'\n",
    "    \n",
    "    # 학습 관련\n",
    "    epochs = 5\n",
    "    batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e2e7223-b10d-4a91-8e38-72509af52dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아키텍쳐 선택\n",
    "# 출처: https://github.com/rwightman/pytorch-image-models/blob/master/timm/models/efficientnet.py\n",
    "class ModelEfficientNet(nn.Module):\n",
    "    # 큰 모델들보다 b4가 좋았음\n",
    "    def __init__(self, model_arch='tf_efficientnet_b4_ns', n_class=18, pretrained=True):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_arch, pretrained=pretrained)\n",
    "        n_features = self.model.classifier.in_features\n",
    "        # 1792, 18로 설정\n",
    "        self.model.classifier = nn.Linear(n_features, n_class)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "class MaskViTClassifier(nn.Module):\n",
    "    def __init__(self, model_arch, n_classes, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_arch, pretrained=pretrained)\n",
    "        n_features = self.model.head.in_features\n",
    "        self.model.head = nn.Linear(n_features, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fb38fe9-4861-4648-af66-cbe2f963f77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss 설정\n",
    "\n",
    "# https://discuss.pytorch.org/t/is-this-a-correct-implementation-for-focal-loss-in-pytorch/43327/8\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, weight=None, gamma=5., reduction='mean'):\n",
    "        nn.Module.__init__(self)\n",
    "        self.weight = weight\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, input_tensor, target_tensor):\n",
    "        log_prob = F.log_softmax(input_tensor, dim=-1)\n",
    "        prob = torch.exp(log_prob)\n",
    "        return F.nll_loss(\n",
    "            ((1 - prob) ** self.gamma) * log_prob,\n",
    "            target_tensor,\n",
    "            weight=self.weight,\n",
    "            reduction=self.reduction\n",
    "        )\n",
    "    \n",
    "    \n",
    "class LabelSmoothingLoss(nn.Module):\n",
    "    def __init__(self, classes=18, smoothing=0.0, dim=-1):\n",
    "        super(LabelSmoothingLoss, self).__init__()\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.cls = classes\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        pred = pred.log_softmax(dim=self.dim)\n",
    "        with torch.no_grad():\n",
    "            true_dist = torch.zeros_like(pred)\n",
    "            true_dist.fill_(self.smoothing / (self.cls - 1))\n",
    "            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b53a7ca-2209-4198-b23f-d431b0d12cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1182/1182 [07:06<00:00,  2.77it/s]\n",
      "100%|██████████| 1182/1182 [07:06<00:00,  2.77it/s]\n",
      "100%|██████████| 1182/1182 [07:05<00:00,  2.78it/s]\n",
      "100%|██████████| 1182/1182 [07:05<00:00,  2.78it/s]\n",
      "100%|██████████| 1182/1182 [07:04<00:00,  2.78it/s]\n"
     ]
    }
   ],
   "source": [
    "# CenterCrop\n",
    "# Normalize\n",
    "# Resize\n",
    "# https://pytorch.org/vision/stable/transforms.html\n",
    "transform = transforms.Compose([ToTensor(), \n",
    "                                Normalize(mean=(0.558, 0.524, 0.499), \n",
    "                                          std=(0.234, 0.243, 0.246))\n",
    "                                ])\n",
    "\n",
    "# Dataset\n",
    "dataset = MaskBaseDataset(img_dir=cfg.train_img_path, transform=transform)\n",
    "\n",
    "\n",
    "#train : val -> 8 : 2\n",
    "n_val = int(len(dataset) * 0.2)\n",
    "n_train = len(dataset) - n_val\n",
    "train_dataset, val_dataset = data.random_split(dataset, [n_train, n_val])\n",
    "\n",
    "\n",
    "# DataLoader\n",
    "# https://pytorch.org/docs/stable/data.html?highlight=dataloader#torch.utils.data.DataLoader\n",
    "train_loader = data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=cfg.batch_size,\n",
    "    num_workers=4,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_loader = data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=cfg.batch_size,\n",
    "    num_workers=4,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "\n",
    "# 학습 안나누고 수행\n",
    "full_loader = data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=cfg.batch_size,\n",
    "    num_workers=4,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "\n",
    "# Model\n",
    "model = ModelEfficientNet().to(device)\n",
    "\n",
    "\n",
    "\n",
    "# CrossEntropy Loss 적용\n",
    "# https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "ls_loss = LabelSmoothingLoss()\n",
    "\n",
    "\n",
    "# Optimizer\n",
    "# https://pytorch.org/docs/stable/optim.html#constructing-it\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-4, weight_decay = 1e-6)\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=1e-4, momentum=0.9)\n",
    "\n",
    "# lr_Scheduler\n",
    "#scheduler = CosineAnnealingWarmUpRestarts(optimizer, T_0=cfg.epochs, T_mult=1, eta_max=1e-5, T_up=1, gamma=0.5)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=cfg.epochs, T_mult=1, eta_min=1e-7)\n",
    "\n",
    "for epoch in range(cfg.epochs):\n",
    "    model.train()\n",
    "    \n",
    "    for inputs, mask_label,gender_label,age_label in tqdm(full_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        mask_label = mask_label.to(device)\n",
    "        gender_label = gender_label.to(device)\n",
    "        age_label = age_label.to(device)\n",
    "        outputs = model(inputs)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        labels = torch.cat([mask_label,gender_label,age_label],dim=-1)\n",
    "\n",
    "        mask_loss = ce_loss(outputs[:,:3],mask_label)\n",
    "        gender_loss = ce_loss(outputs[:,3:5],gender_label)\n",
    "        age_loss = ls_loss(outputs[:,5:8],age_label)        \n",
    "        \n",
    "        loss = (mask_loss+gender_loss+age_loss)/3\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2968b98c-dc5d-45c8-b7ed-656d6177b02d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12600/12600 [10:11<00:00, 20.60it/s]\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize,CenterCrop\n",
    "class TestDataset(data.Dataset):\n",
    "    def __init__(self, img_paths, transform):\n",
    "        self.img_paths = img_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.img_paths[index])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "\n",
    "# meta 데이터와 이미지 경로를 불러옵니다.\n",
    "submission = pd.read_csv(cfg.test_path + 'info.csv')\n",
    "image_dir = os.path.join(cfg.test_img_path)\n",
    "\n",
    "\n",
    "# Test Dataset 클래스 객체를 생성하고 DataLoader를 만듭니다.\n",
    "image_paths = [os.path.join(image_dir, img_id) for img_id in submission.ImageID]\n",
    "\n",
    "transform = transforms.Compose([ToTensor(), \n",
    "                                Normalize(mean=(0.558, 0.524, 0.499), \n",
    "                                          std=(0.234, 0.243, 0.246))\n",
    "                                ])\n",
    "\n",
    "dataset = TestDataset(image_paths, transform)\n",
    "\n",
    "loader = data.DataLoader(\n",
    "    dataset,\n",
    "    shuffle=False\n",
    ")\n",
    "# 모델을 정의합니다. (학습한 모델이 있다면 torch.load로 모델을 불러주세요!)\n",
    "\n",
    "\n",
    "model.eval()\n",
    "\n",
    "\n",
    "# 모델이 테스트 데이터셋을 예측하고 결과를 저장합니다.\n",
    "all_predictions = []\n",
    "for images in tqdm(loader):\n",
    "    with torch.no_grad():\n",
    "        images = images.to(device)\n",
    "        pred = model(images)\n",
    "        mask_pred = pred[:,:3].argmax(dim=-1) # mask classification\n",
    "        gender_pred = pred[:,3:5].argmax(dim=-1) # gender classiification\n",
    "        age_pred = pred[:,5:].argmax(dim=-1) # age classification\n",
    "        pred = (mask_pred * 6 + gender_pred * 3 + age_pred).cpu().numpy()\n",
    "        all_predictions.extend(pred)\n",
    "submission['ans'] = all_predictions\n",
    "\n",
    "\n",
    "\n",
    "# 제출할 파일을 저장합니다. / submission(033_2_5_0303).csv\n",
    "submission.to_csv(cfg.test_path + 'submission(full_effb4_05_16).csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75c21e2e-765e-493c-b26b-f573b5f30924",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,'full_effb4_05_16.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e11f256-16ea-4e3f-890c-6eebb8779cc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2db31c0-8078-4ef0-9f7a-10e643d12c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import models,transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from typing import Tuple, List\n",
    "import torch\n",
    "from torch import optim,nn\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dataset import MaskDataset, AddGaussianNoise\n",
    "from models import get_pre_trained\n",
    "\n",
    "data_dir = '../../input/data/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73f2d175-b5d0-4493-a27f-82614831f71f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/opt/ml/level1-image-classification-level1-recsys-08/code'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d394d76-ecde-4fc5-b99f-e5568f05b6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'densenet161'\n",
    "# model_name = 'resnet50'\n",
    "num_classes = 18\n",
    "# Initialize the model for this run\n",
    "model = get_pre_trained(model_name, feature_extract = False, pretrained = True)\n",
    "# Define the device:\n",
    "device = torch.device('cuda:0')\n",
    "# Put the model on the device:\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43303f31-a08e-4bf1-937d-02b5c302cf7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upsamling starts ...\n",
      "Data split completed: val_ratio=0.1\n",
      "n_train=26064, n_val=2895\n"
     ]
    }
   ],
   "source": [
    "norm_mean = (0.485, 0.456, 0.406)\n",
    "norm_std = (0.229, 0.224, 0.225)\n",
    "\n",
    "train_transform = transforms.Compose([transforms.RandomRotation(degrees = 15),\n",
    "                                      transforms.ColorJitter(brightness=0.1, contrast=0.1, hue=0.1),\n",
    "                                      transforms.RandomVerticalFlip(p=0.5),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize(norm_mean, norm_std),\n",
    "#                                       AddGaussianNoise()\n",
    "                                     ])\n",
    "val_transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                    transforms.Normalize(norm_mean, norm_std)])\n",
    "\n",
    "dataset = MaskDataset(data_dir=data_dir,transforms=train_transform, adj_csv = True, val_ratio=0.1, up_sampling = 3)\n",
    "batch_size = 16\n",
    "train_set, val_set = dataset.split_dataset()\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    pin_memory=use_cuda,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    pin_memory=use_cuda,\n",
    "    drop_last=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3eced3f0-d710-4a9b-9696-e3139ab013fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function is used during training process, to calculation the loss and accuracy\n",
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a430e703-4ec6-4c4e-b1c5-20dd894cd3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer, epoch):\n",
    "    save_dir = os.path.join(os.getcwd(), 'save')\n",
    "    model.train()\n",
    "    train_loss = AverageMeter()\n",
    "    train_acc = AverageMeter()\n",
    "    curr_iter = (epoch - 1) * len(train_loader)\n",
    "    \n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    \n",
    "    for i, data in enumerate(train_loader):\n",
    "        images, labels = data\n",
    "        N = images.size(0)\n",
    "        # print('image shape:',images.size(0), 'label shape',labels.size(0))\n",
    "        images = Variable(images).to(device)\n",
    "        labels = Variable(labels).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        prediction = outputs.max(1, keepdim=True)[1]\n",
    "        train_acc.update(prediction.eq(labels.view_as(prediction)).sum().item()/N)\n",
    "        train_loss.update(loss.item())\n",
    "        curr_iter += 1\n",
    "        if (i + 1) % 200 == 0:\n",
    "            print('[epoch %d], [iter %d / %d], [train loss %.5f], [train acc %.5f]' % (\n",
    "                epoch, i + 1, len(train_loader), train_loss.avg, train_acc.avg))\n",
    "            total_loss_train.append(train_loss.avg)\n",
    "            total_acc_train.append(train_acc.avg)\n",
    "    return train_loss.avg, train_acc.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d61c83d-3d7f-41bf-85c0-ed6c1a854b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader, criterion, optimizer, epoch):\n",
    "    model.eval()\n",
    "    val_loss = AverageMeter()\n",
    "    val_acc = AverageMeter()\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(val_loader):\n",
    "            images, labels = data\n",
    "            N = images.size(0)\n",
    "            images = Variable(images).to(device)\n",
    "            labels = Variable(labels).to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            prediction = outputs.max(1, keepdim=True)[1]\n",
    "\n",
    "            val_acc.update(prediction.eq(labels.view_as(prediction)).sum().item()/N)\n",
    "\n",
    "            val_loss.update(criterion(outputs, labels).item())\n",
    "\n",
    "    print('------------------------------------------------------------')\n",
    "    print('[epoch %d], [val loss %.5f], [val acc %.5f]' % (epoch, val_loss.avg, val_acc.avg))\n",
    "    print('------------------------------------------------------------')\n",
    "    return val_loss.avg, val_acc.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01dcd83-7c6a-4749-a152-a95a66220836",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1], [iter 200 / 1629], [train loss 2.12937], [train acc 0.30406]\n",
      "[epoch 1], [iter 400 / 1629], [train loss 1.81498], [train acc 0.39563]\n",
      "[epoch 1], [iter 600 / 1629], [train loss 1.58529], [train acc 0.46479]\n",
      "[epoch 1], [iter 800 / 1629], [train loss 1.43412], [train acc 0.50758]\n",
      "[epoch 1], [iter 1000 / 1629], [train loss 1.32533], [train acc 0.54131]\n",
      "[epoch 1], [iter 1200 / 1629], [train loss 1.23563], [train acc 0.56776]\n",
      "[epoch 1], [iter 1400 / 1629], [train loss 1.15487], [train acc 0.59487]\n",
      "[epoch 1], [iter 1600 / 1629], [train loss 1.09273], [train acc 0.61535]\n",
      "------------------------------------------------------------\n",
      "[epoch 1], [val loss 0.57674], [val acc 0.78333]\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 1/12 [28:18<5:11:28, 1698.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************************\n",
      "best record: [epoch 1], [val loss 0.57674], [val acc 0.78333]\n",
      "*****************************************************\n",
      "[epoch 2], [iter 200 / 1629], [train loss 0.58204], [train acc 0.78063]\n",
      "[epoch 2], [iter 400 / 1629], [train loss 0.57304], [train acc 0.78781]\n",
      "[epoch 2], [iter 600 / 1629], [train loss 0.56716], [train acc 0.78969]\n",
      "[epoch 2], [iter 800 / 1629], [train loss 0.55185], [train acc 0.79578]\n",
      "[epoch 2], [iter 1000 / 1629], [train loss 0.54184], [train acc 0.79981]\n",
      "[epoch 2], [iter 1200 / 1629], [train loss 0.53668], [train acc 0.80156]\n",
      "[epoch 2], [iter 1400 / 1629], [train loss 0.53131], [train acc 0.80286]\n",
      "[epoch 2], [iter 1600 / 1629], [train loss 0.52529], [train acc 0.80625]\n",
      "------------------------------------------------------------\n",
      "[epoch 2], [val loss 0.41792], [val acc 0.84583]\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 2/12 [56:25<4:41:58, 1691.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************************\n",
      "best record: [epoch 2], [val loss 0.41792], [val acc 0.84583]\n",
      "*****************************************************\n",
      "[epoch 3], [iter 200 / 1629], [train loss 0.43187], [train acc 0.83625]\n",
      "[epoch 3], [iter 400 / 1629], [train loss 0.42654], [train acc 0.83859]\n",
      "[epoch 3], [iter 600 / 1629], [train loss 0.41594], [train acc 0.84240]\n",
      "[epoch 3], [iter 800 / 1629], [train loss 0.41041], [train acc 0.84695]\n",
      "[epoch 3], [iter 1000 / 1629], [train loss 0.40247], [train acc 0.84925]\n",
      "[epoch 3], [iter 1200 / 1629], [train loss 0.39923], [train acc 0.85250]\n",
      "[epoch 3], [iter 1400 / 1629], [train loss 0.39424], [train acc 0.85460]\n",
      "[epoch 3], [iter 1600 / 1629], [train loss 0.38863], [train acc 0.85672]\n",
      "------------------------------------------------------------\n",
      "[epoch 3], [val loss 0.38322], [val acc 0.86667]\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 3/12 [1:24:28<4:13:07, 1687.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************************\n",
      "best record: [epoch 3], [val loss 0.38322], [val acc 0.86667]\n",
      "*****************************************************\n",
      "[epoch 4], [iter 200 / 1629], [train loss 0.28535], [train acc 0.89125]\n",
      "[epoch 4], [iter 400 / 1629], [train loss 0.30734], [train acc 0.88484]\n",
      "[epoch 4], [iter 600 / 1629], [train loss 0.31653], [train acc 0.88104]\n",
      "[epoch 4], [iter 800 / 1629], [train loss 0.32161], [train acc 0.88156]\n",
      "[epoch 4], [iter 1000 / 1629], [train loss 0.31136], [train acc 0.88681]\n",
      "[epoch 4], [iter 1200 / 1629], [train loss 0.30777], [train acc 0.88854]\n",
      "[epoch 4], [iter 1400 / 1629], [train loss 0.30370], [train acc 0.89107]\n",
      "[epoch 4], [iter 1600 / 1629], [train loss 0.30376], [train acc 0.89086]\n",
      "------------------------------------------------------------\n",
      "[epoch 4], [val loss 0.26056], [val acc 0.90833]\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 4/12 [1:52:27<3:44:35, 1684.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************************\n",
      "best record: [epoch 4], [val loss 0.26056], [val acc 0.90833]\n",
      "*****************************************************\n",
      "[epoch 5], [iter 200 / 1629], [train loss 0.23718], [train acc 0.91344]\n",
      "[epoch 5], [iter 400 / 1629], [train loss 0.24814], [train acc 0.90953]\n",
      "[epoch 5], [iter 600 / 1629], [train loss 0.25016], [train acc 0.90719]\n",
      "[epoch 5], [iter 800 / 1629], [train loss 0.24509], [train acc 0.91031]\n",
      "[epoch 5], [iter 1000 / 1629], [train loss 0.24591], [train acc 0.91075]\n",
      "[epoch 5], [iter 1200 / 1629], [train loss 0.24698], [train acc 0.91057]\n",
      "[epoch 5], [iter 1400 / 1629], [train loss 0.24394], [train acc 0.91219]\n",
      "[epoch 5], [iter 1600 / 1629], [train loss 0.24277], [train acc 0.91258]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 5/12 [2:20:14<3:15:46, 1678.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "[epoch 5], [val loss 0.31443], [val acc 0.88854]\n",
      "------------------------------------------------------------\n",
      "[epoch 6], [iter 200 / 1629], [train loss 0.20185], [train acc 0.92812]\n",
      "[epoch 6], [iter 400 / 1629], [train loss 0.20293], [train acc 0.92906]\n",
      "[epoch 6], [iter 600 / 1629], [train loss 0.21326], [train acc 0.92531]\n",
      "[epoch 6], [iter 800 / 1629], [train loss 0.21240], [train acc 0.92555]\n",
      "[epoch 6], [iter 1000 / 1629], [train loss 0.21230], [train acc 0.92563]\n",
      "[epoch 6], [iter 1200 / 1629], [train loss 0.20969], [train acc 0.92651]\n",
      "[epoch 6], [iter 1400 / 1629], [train loss 0.21021], [train acc 0.92612]\n",
      "[epoch 6], [iter 1600 / 1629], [train loss 0.21058], [train acc 0.92668]\n",
      "------------------------------------------------------------\n",
      "[epoch 6], [val loss 0.14830], [val acc 0.94583]\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 6/12 [2:48:23<2:48:09, 1681.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************************\n",
      "best record: [epoch 6], [val loss 0.14830], [val acc 0.94583]\n",
      "*****************************************************\n",
      "[epoch 7], [iter 200 / 1629], [train loss 0.15859], [train acc 0.94906]\n",
      "[epoch 7], [iter 400 / 1629], [train loss 0.16268], [train acc 0.94563]\n",
      "[epoch 7], [iter 600 / 1629], [train loss 0.16378], [train acc 0.94615]\n",
      "[epoch 7], [iter 800 / 1629], [train loss 0.16651], [train acc 0.94352]\n",
      "[epoch 7], [iter 1000 / 1629], [train loss 0.17140], [train acc 0.94144]\n",
      "[epoch 7], [iter 1200 / 1629], [train loss 0.16865], [train acc 0.94255]\n",
      "[epoch 7], [iter 1400 / 1629], [train loss 0.17082], [train acc 0.94219]\n",
      "[epoch 7], [iter 1600 / 1629], [train loss 0.17066], [train acc 0.94215]\n",
      "------------------------------------------------------------\n",
      "[epoch 7], [val loss 0.12730], [val acc 0.95903]\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 7/12 [3:16:21<2:20:03, 1680.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************************\n",
      "best record: [epoch 7], [val loss 0.12730], [val acc 0.95903]\n",
      "*****************************************************\n",
      "[epoch 8], [iter 200 / 1629], [train loss 0.13264], [train acc 0.95562]\n",
      "[epoch 8], [iter 400 / 1629], [train loss 0.14534], [train acc 0.95172]\n",
      "[epoch 8], [iter 600 / 1629], [train loss 0.14590], [train acc 0.95010]\n",
      "[epoch 8], [iter 800 / 1629], [train loss 0.14502], [train acc 0.94977]\n",
      "[epoch 8], [iter 1000 / 1629], [train loss 0.15065], [train acc 0.94781]\n",
      "[epoch 8], [iter 1200 / 1629], [train loss 0.15058], [train acc 0.94729]\n",
      "[epoch 8], [iter 1400 / 1629], [train loss 0.14530], [train acc 0.94937]\n",
      "[epoch 8], [iter 1600 / 1629], [train loss 0.14487], [train acc 0.95000]\n",
      "------------------------------------------------------------\n",
      "[epoch 8], [val loss 0.11751], [val acc 0.96076]\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 8/12 [3:44:20<1:51:59, 1679.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************************\n",
      "best record: [epoch 8], [val loss 0.11751], [val acc 0.96076]\n",
      "*****************************************************\n",
      "[epoch 9], [iter 200 / 1629], [train loss 0.14386], [train acc 0.94688]\n",
      "[epoch 9], [iter 400 / 1629], [train loss 0.12316], [train acc 0.95562]\n",
      "[epoch 9], [iter 600 / 1629], [train loss 0.13710], [train acc 0.95188]\n",
      "[epoch 9], [iter 800 / 1629], [train loss 0.13441], [train acc 0.95258]\n",
      "[epoch 9], [iter 1000 / 1629], [train loss 0.13868], [train acc 0.95156]\n",
      "[epoch 9], [iter 1200 / 1629], [train loss 0.13273], [train acc 0.95464]\n",
      "[epoch 9], [iter 1400 / 1629], [train loss 0.13084], [train acc 0.95549]\n",
      "[epoch 9], [iter 1600 / 1629], [train loss 0.13093], [train acc 0.95559]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 9/12 [4:12:13<1:23:53, 1677.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "[epoch 9], [val loss 0.16034], [val acc 0.94444]\n",
      "------------------------------------------------------------\n",
      "[epoch 10], [iter 200 / 1629], [train loss 0.10640], [train acc 0.96031]\n",
      "[epoch 10], [iter 400 / 1629], [train loss 0.13383], [train acc 0.95359]\n",
      "[epoch 10], [iter 600 / 1629], [train loss 0.11882], [train acc 0.95917]\n",
      "[epoch 10], [iter 800 / 1629], [train loss 0.11265], [train acc 0.96164]\n",
      "[epoch 10], [iter 1000 / 1629], [train loss 0.11292], [train acc 0.96113]\n",
      "[epoch 10], [iter 1200 / 1629], [train loss 0.11925], [train acc 0.95917]\n",
      "[epoch 10], [iter 1400 / 1629], [train loss 0.11855], [train acc 0.96000]\n",
      "[epoch 10], [iter 1600 / 1629], [train loss 0.11663], [train acc 0.96070]\n"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = '../model' + '/' + model_name\n",
    "os.makedirs(MODEL_PATH, exist_ok=True)\n",
    "epoch_num = 12\n",
    "best_val_acc = 0\n",
    "total_loss_train, total_acc_train = [],[]\n",
    "total_loss_val, total_acc_val = [],[]\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "for epoch in tqdm(range(1, epoch_num+1)):\n",
    "    loss_train, acc_train = train(model, train_loader, criterion, optimizer, epoch)\n",
    "    loss_val, acc_val = validate(model, val_loader, criterion, optimizer, epoch)\n",
    "    total_loss_val.append(loss_val)\n",
    "    total_acc_val.append(acc_val)\n",
    "    if acc_val > best_val_acc:\n",
    "        best_val_acc = acc_val\n",
    "        torch.save(model.state_dict(), os.path.join(MODEL_PATH, f\"{model_name}_best.pt\"))\n",
    "        print('*****************************************************')\n",
    "        print('best record: [epoch %d], [val loss %.5f], [val acc %.5f]' % (epoch, loss_val, acc_val))\n",
    "        print('*****************************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0326d3d9-0215-4dbd-bdfd-e18834e6db64",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(num = 2, figsize = (12,6))\n",
    "fig1 = fig.add_subplot(2,1,1)\n",
    "fig2 = fig.add_subplot(2,1,2)\n",
    "fig1.plot(total_loss_train, label = 'training loss')\n",
    "fig1.plot(total_acc_train, label = 'training accuracy')\n",
    "fig1.legend()\n",
    "fig2.plot(total_loss_val, label = 'validation loss')\n",
    "fig2.plot(total_acc_val, label = 'validation accuracy')\n",
    "fig2.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759e0062-ad4d-4b3d-a6e4-69dedce54dd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
